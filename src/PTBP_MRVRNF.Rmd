---
title: 'The Pediatric Template of Brain Perfusion: MRVNRF with *ANTsR*'
author: "Brian B. Avants et al."
date: "`r Sys.Date()`"
output:
  beamer_presentation:
    colortheme: dolphin
    fonttheme: structurebold
    highlight: tango
    incremental: yes
    theme: AnnArbor
    includes:
      in_header: mystyle.tex
    toc: yes
  ioslides_presentation:
    highlight: tango
    incremental: yes
---

```{r setup,eval=TRUE,results='hide',warning=FALSE,echo=FALSE}
# set this for your own compilation
set.seed(1000)
bd="/Users/stnava/data/ANTsTutorial/"
```

# MRVNRF with ANTsR

## Extension of a recent paper

[**BRATS Challenge**](http://www.ncbi.nlm.nih.gov/pubmed/25433513)

> Tustison et al

* difference 1: here, using multiple resolution RFs

* difference 2: predicting a continuous outcome ...


## Basic Setup

```{r dataio}
library(ANTsR)
library(visreg)
library(randomForest)
thkmask=antsImageRead( paste(bd,"data/ptbp_mask_thickness.nii.gz",sep='') )
famask=antsImageRead( paste(bd,"data/ptbp_mask_fa.nii.gz",sep='') )
demog=read.csv("/Users/stnava/data/ANTsTutorial/data/ptbp_summary_demographics.csv")
demog=demog[ , 1:19 ]
```

## Get all voxel data

```{r form}
thkmat=antsImageRead( paste(bd,"data/ptbp_vox_thk.mha",sep='') )
famat=antsImageRead( paste(bd,"data/ptbp_vox_fa.mha",sep='') )
cbfmat=antsImageRead( paste(bd,"data/ptbp_vox_cbf.mha",sep='') )
thkmat=as.matrix( thkmat )
cbfmat=as.matrix( cbfmat )
famat=as.matrix( famat )
```

## Get common images and make a dataframe

```{r subsel,echo=FALSE}
wp=( !is.na(rowMeans(thkmat)) & rowMeans(thkmat) > 0.5  &
     !is.na(rowMeans(famat)) & rowMeans(famat) > 0.2  &
     !is.na(rowMeans(cbfmat)) & rowMeans(cbfmat) > 40 )
for ( x in unique( demog$SubID ) )
  {
  kk=which( demog$SubID == x )
  if ( length(kk) > 1 ) wp[ kk[2:length(kk)] ] = FALSE
  }
```

```{r mdf}
mydf=data.frame( AgeAtScan=demog[wp,]$AgeAtScan,
   #             PIQ=demog[wp,]$Performance.IQ,
                 VIQ=demog[wp,]$Verbal.IQ,
                 BV=demog[wp,]$BV,
                 Cortex=demog[wp,]$Cortex,
    #           LadderCom=demog[wp,]$Teen.Ladder.Community.Score,
    #            LadderSES=demog[wp,]$Teen.Ladder.SES.score,
                 Income=demog[wp,]$Income )
for ( kk in 2:ncol(mydf) ) mydf[,kk]=antsrimpute( mydf[,kk] )
```  

# Cross-validation and Feature Selection


## Train/Test

First get the data organized.
```{r orgpred}
library(randomForest)
groups <- rep( c(1,2), 1000 )[1:nrow(mydf)]
traing=groups==1
testg=groups==2
```

## Select thickness zones related to VIQ ( our outcome )


```{r fselth,echo=FALSE}
y=mydf$VIQ[traing]
temp=thkmat[wp,][traing,]
thkR2=colMeans(
  crossvalidatedR2( temp, y, ngroups=4 ) )
thkR2[ abs(thkR2) > 1.e9 ]=0
thkR2[ thkR2 < 0 ]=0
thkR2img=makeImage( thkmask, thkR2 ) %>%
  smoothImage(1)
plot( thkmask, thkR2img, axis=3, nslices=16,
  window.overlay=c(1,max(thkR2img)) )
```

## Select FA zones related to VIQ ( our outcome )

```{r fselfa,echo=FALSE}
temp=famat[wp,][traing,]
faR2=colMeans(
  crossvalidatedR2( temp, y, ngroups=4 ) )
faR2[ abs(faR2) > 1.e9 ]=0
faR2[ faR2 < 0 ]=0
faR2img=makeImage( famask, faR2 ) %>%
  smoothImage(1)
plot( famask, faR2img, axis=3, nslices=16,
  window.overlay=c(1,max(faR2img)) )
```

## Select CBF zones related to VIQ ( our outcome )

```{r fselcbf,echo=FALSE}
temp=cbfmat[wp,][traing,]
cbfR2=colMeans(
  crossvalidatedR2( temp, y, ngroups=4 ) )
cbfR2[ abs(cbfR2) > 1.e9 ]=0
cbfR2[ cbfR2 < 0 ]=0
cbfR2img=makeImage( thkmask, cbfR2 ) %>%
  smoothImage(1)
plot( thkmask, cbfR2img, axis=3, nslices=16,
  window.overlay=c(1,max(cbfR2img)) )
```

## Merge the images to establish a single mask

```{r maskmerge}
mrvR2=cbfR2img+faR2img+thkR2img
thr2=2
mrvmask=thresholdImage( mrvR2, thr2, Inf )
thr4=4
mrvmask4=thresholdImage( mrvR2, thr4, Inf )
mrvmask4=labelClusters( mrvmask4,
  minClusterSize=10 )
```

## MRVNRF Mask

```{r mrviz3,echo=FALSE}
plot( thkmask, mrvR2, axis=3, nslices=16,
   window.overlay=c(thr4, max(mrvR2) ) )
```

## MRVNRF Mask: After surgery

```{r mrviz4,echo=FALSE}
plot( thkmask, mrvmask4, axis=3, nslices=16,
   window.overlay=c(1, max(mrvmask4) ) )
mrvmask4=thresholdImage( mrvmask4, 1, Inf )
nmask=sum( mrvmask4 == 1 )
```

# MRVNRF Setup and Algorithm

## Set up mrvnrfs

```{r mrvsubs}
slist=list()
agelist=list()
ct=1
for ( x in which(wp) )
  {
  if (  wp[x] == TRUE )
    {
    i1=makeImage(thkmask, thkmat[x,])
    i2=makeImage(famask, famat[x,])
    i3=makeImage(thkmask, cbfmat[x,] )
    feati=list( i1 , i2 )
    slist[[ct]]=feati
    agelist[[ct]]=mydf$VIQ[x]
    ct=ct+1
    }
  }
rm( thkmat )
rm( famat )
rm( cbfmat )
gc()
```

## MRVNRF Train

We train from the CBF, FA and cortical thickness images.

```{r mrvtrain}
y=mydf$VIQ[traing]
x=slist[traing]
mr=c(4,2)
if ( ! exists("rfm") )
rfm<-mrvnrfs( y, x,
  mrvmask4, rad=rep(1,3),
  nsamples=nmask/10, ntrees=2000,
  multiResSchedule=mr,
  asFactors = FALSE )
```


## MRVNRF Test

```{r mrvtest}
if ( ! exists("rfm2") )
rfm2<-mrvnrfs.predict( rfm$rflist,
  slist[testg], mrvmask4, rad=rep(1,3),
  multiResSchedule=mr,
  asFactors = FALSE )
cor( mydf$VIQ[testg] , rfm2$seg )
print(  mean( abs( mydf$VIQ[testg] - rfm2$seg) ) )
```

# MRVNRF Results

## MRVNRF Viz

```{r mrviz}
predmat<-imageListToMatrix( unlist(rfm2$probs) , mrvmask4 )
rfpred <- apply( predmat,  FUN = median, MARGIN = 1)
print(  cor.test( mydf$VIQ[testg] , rfpred ) )
print(  mean( abs( mydf$VIQ[testg] - rfpred) ) )
corrmat<-antsrimpute( cor( predmat , mydf$VIQ[testg] ) )
corimg<-makeImage( mrvmask4, corrmat )
```

## MRVNRF Viz

```{r mrviz2,echo=FALSE}
plot( thkmask, corimg, axis=3, nslices=16,
   window.overlay=c( 0.1 , max(corimg) ) )
```

## Investigate the final model (single regression predicting VIQ)

```{r mrvmdl,echo=FALSE}
temp=mydf[testg,]
mrvdf=data.frame( temp , mrvpred=rfpred )
mrvmdl=lm( VIQ ~ AgeAtScan + BV + Income + mrvpred , data=mrvdf )
m_table <- broom::tidy(mrvmdl)
knitr::kable(m_table, digits = 3, align = "r",
      col.names = c("Param", "B", "SE", "t", "p"))
```

# Done!

## Discussion

* MRV-NRF:  Multiple resolution

* MRV-NRF:  voxel-wise

* MRV-NRF:  neighborhood

* MRV-NRF:  random forest ...

* High-dimensional, non-local predictions from multiple modalities

* Powerful, yet remains interpretable in terms of
traditional statistical studies.

* .... but how did we get the final "single" prediction?
